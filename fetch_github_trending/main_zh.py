#!/usr/bin/env python3
"""
GitHub Trending MCP Server

ä¸€ä¸ªä¸“é—¨ç”¨äºåˆ†æGitHubä¸Šçƒ­é—¨é¡¹ç›®çš„MCPæœåŠ¡å™¨ã€‚
æ­¤æœåŠ¡å™¨å¸®åŠ©AIåŠ©æ‰‹å‘ç°ã€åˆ†æå’Œç†è§£GitHubä¸Šçš„çƒ­é—¨é¡¹ç›®åŠå…¶å®ç°ã€‚

ä½¿ç”¨æµç¨‹ï¼š
1. é¦–å…ˆè°ƒç”¨ get_github_trending æ¥å‘ç°çƒ­é—¨ä»“åº“ï¼ˆå¯æŒ‡å®šæ—¶é—´èŒƒå›´å’Œç¼–ç¨‹è¯­è¨€ï¼‰
2. ç„¶åè°ƒç”¨ get_repository_readme æ¥è·å–é€‰å®šä»“åº“çš„è¯¦ç»†æ–‡æ¡£
3. åˆ†æå’Œæ€»ç»“é¡¹ç›®çš„å®ç°å’Œæ–¹æ³•
"""

import requests
from bs4 import BeautifulSoup
import re
from typing import List
from datetime import datetime
from fastmcp import FastMCP

# åˆ›å»ºMCP serverå®ä¾‹
mcp = FastMCP("GitHub Trending Analyzer")


@mcp.tool()
def get_github_trending(since: str = "daily", language: str = "") -> str:
    """
    è·å–GitHub trendingæ¦œå•

    æ­¤å·¥å…·çˆ¬å–GitHub trendingé¡µé¢ï¼Œæå–è¶‹åŠ¿é¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯ã€‚

    å‚æ•°è¯´æ˜ï¼š
    - since: æ—¶é—´èŒƒå›´ï¼Œå¯é€‰å€¼ä¸º "daily"ï¼ˆæ—¥ï¼‰ã€"weekly"ï¼ˆå‘¨ï¼‰ã€"monthly"ï¼ˆæœˆï¼‰ï¼Œé»˜è®¤ä¸º "daily"
    - language: ç¼–ç¨‹è¯­è¨€è¿‡æ»¤ï¼Œä¾‹å¦‚ "python"ã€"javascript"ã€"go" ç­‰ï¼Œé»˜è®¤ä¸ºç©ºï¼ˆæ‰€æœ‰è¯­è¨€ï¼‰

    è¿”å›ç»“æœåŒ…å«é¡¹ç›®åç§°ã€æè¿°ã€ç¼–ç¨‹è¯­è¨€ã€æ˜Ÿæ•°ã€å¢é•¿ç­‰ä¿¡æ¯ã€‚
    """
    # éªŒè¯æ—¶é—´èŒƒå›´å‚æ•°
    valid_since = ["daily", "weekly", "monthly"]
    if since not in valid_since:
        return f"âŒ é”™è¯¯ï¼šsinceå‚æ•°å¿…é¡»æ˜¯ä»¥ä¸‹å€¼ä¹‹ä¸€: {', '.join(valid_since)}"

    # æ„å»ºURL
    if language:
        url = f"https://github.com/trending/{language.lower()}?since={since}"
    else:
        url = f"https://github.com/trending?since={since}"

    try:
        # è·å–å½“å‰æ—¥æœŸä¿¡æ¯
        current_date = datetime.now()
        date_str = current_date.strftime("%Yå¹´%mæœˆ%dæ—¥")
        weekday_names = ["æ˜ŸæœŸä¸€", "æ˜ŸæœŸäºŒ", "æ˜ŸæœŸä¸‰", "æ˜ŸæœŸå››", "æ˜ŸæœŸäº”", "æ˜ŸæœŸå…­", "æ˜ŸæœŸæ—¥"]
        weekday_str = weekday_names[current_date.weekday()]

        # æ—¶é—´èŒƒå›´æ˜¾ç¤º
        since_display = {"daily": "ä»Šæ—¥", "weekly": "æœ¬å‘¨", "monthly": "æœ¬æœˆ"}

        # ç®€å•çš„requestsè¯·æ±‚
        response = requests.get(url, timeout=30)
        response.raise_for_status()

        soup = BeautifulSoup(response.content, 'html.parser')
        articles = soup.find_all('article', class_='Box-row')

        if not articles:
            return f"âŒ æœªæ‰¾åˆ°ä»»ä½•trendingé¡¹ç›®ï¼Œå¯èƒ½é¡µé¢ç»“æ„å·²æ›´æ”¹æˆ–ç½‘ç»œé—®é¢˜\nè¯·æ±‚URL: {url}"

        result = []
        result.append(f"ğŸŒŸ GitHub Trending Repositories")
        result.append(f"ğŸ“… è·å–æ—¶é—´: {date_str} {weekday_str}")
        result.append(f"â° æ—¶é—´èŒƒå›´: {since_display.get(since, since)}")
        if language:
            result.append(f"ğŸ’» ç¼–ç¨‹è¯­è¨€: {language}")
        result.append(f"ğŸ“Š å…±å‘ç° {len(articles)} ä¸ªçƒ­é—¨é¡¹ç›®")
        result.append("")

        for i, article in enumerate(articles, 1):
            try:
                # æå–æ ‡é¢˜
                title_elem = article.find('h2', class_='h3')
                if not title_elem:
                    continue

                title_link = title_elem.find('a')
                if not title_link:
                    continue

                title = ' '.join(title_link.get_text(strip=True).split())
                project_url = "https://github.com" + title_link.get('href', '')

                # æå–ç®€ä»‹
                description_elem = article.find('p', class_='col-9')
                description = description_elem.get_text(strip=True) if description_elem else "æ— æè¿°"

                # æå–ç¼–ç¨‹è¯­è¨€
                language_elem = article.find('span', {'itemprop': 'programmingLanguage'})
                project_language = language_elem.get_text(strip=True) if language_elem else "æœªçŸ¥"

                # æå–æ€»æ˜Ÿæ ‡æ•°é‡
                star_link = article.find('a', href=re.compile(r'/stargazers$'))
                total_stars = star_link.get_text(strip=True) if star_link else "0"

                # æå–forkæ•°é‡
                fork_link = article.find('a', href=re.compile(r'/forks$'))
                total_forks = fork_link.get_text(strip=True) if fork_link else "0"

                # æå–æ—¶é—´æ®µå†…çš„æ˜Ÿæ ‡æ•°é‡
                period_stars = "0"
                spans = article.find_all('span')
                for span in spans:
                    span_text = span.get_text(strip=True)
                    if 'stars' in span_text.lower() and (
                            'today' in span_text.lower() or 'this week' in span_text.lower() or 'this month' in span_text.lower()):
                        period_match = re.search(r'(\d+[,\d]*)\s*stars?', span_text, re.IGNORECASE)
                        if period_match:
                            period_stars = period_match.group(1)
                        break

                result.append(f"{i}. {title}")
                result.append(f"   ğŸ”— {project_url}")
                result.append(f"   ğŸ“ {description}")
                result.append(
                    f"   ğŸ’» è¯­è¨€: {project_language} | â­ æ€»æ˜Ÿæ•°: {total_stars} | ğŸ´ Forks: {total_forks} | ğŸ”¥ {since_display.get(since, since)}: +{period_stars}")

            except Exception as e:
                result.append(f"âŒ è§£æç¬¬ {i} ä¸ªé¡¹ç›®æ—¶å‡ºé”™: {str(e)}")
                continue

        result.append("")
        result.append("ğŸ’¡ å»ºè®®ä¸‹ä¸€æ­¥æ“ä½œï¼š")
        result.append("1. åˆ†æGitHubçƒ­é—¨é¡¹ç›®è¶‹åŠ¿")
        result.append("2. å¦‚æœ‰ç‰¹åˆ«å…³æ³¨çš„é¡¹ç›®ï¼Œå¯ä½¿ç”¨ get_repository_readme å·¥å…·è·å–è¯¥é¡¹ç›®è¯¦ç»†æ–‡æ¡£")

        return "\n".join(result)

    except requests.exceptions.RequestException as e:
        return f"âŒ ç½‘ç»œè¯·æ±‚é”™è¯¯: {str(e)}\nè¯·æ±‚URL: {url}\nå»ºè®®æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•"
    except Exception as e:
        return f"âŒ ç¨‹åºæ‰§è¡Œé”™è¯¯: {str(e)}\nè¯·æ±‚URL: {url}"


@mcp.tool()
def get_repository_readme(repositories: List[str]) -> str:
    """
    è·å–æŒ‡å®šGitHubä»“åº“çš„READMEæ–‡æ¡£å†…å®¹

    æ­¤å·¥å…·ç”¨äºè·å–GitHubä»“åº“çš„è¯¦ç»†æ–‡æ¡£ã€‚

    å‚æ•°è¯´æ˜ï¼š
    - repositories: ä»“åº“åç§°åˆ—è¡¨ï¼Œæ ¼å¼ä¸º ["owner/repo-name"]
    """
    if not repositories:
        return "âŒ é”™è¯¯ï¼šrepositorieså‚æ•°ä¸èƒ½ä¸ºç©ºï¼Œè¯·æä¾›è‡³å°‘ä¸€ä¸ªä»“åº“åç§°"

    results = []
    results.append("ğŸ“š GitHub Repository README Documents")

    for repo in repositories:
        try:
            # æ¸…ç†ä»“åº“åç§°
            repo = repo.strip()
            if not repo:
                continue

            # éªŒè¯ä»“åº“åç§°æ ¼å¼
            if '/' not in repo:
                results.append(f"âŒ ä»“åº“åç§°æ ¼å¼é”™è¯¯: {repo}")
                results.append("   æ­£ç¡®æ ¼å¼åº”ä¸º: owner/repository-name")
                results.append("---")
                results.append("")
                continue

            # å°è¯•ä¸åŒçš„åˆ†æ”¯å’Œæ–‡ä»¶å
            branches = ['main', 'master']
            readme_files = ['README.md', 'readme.md', 'Readme.md', 'README.txt', 'readme.txt']

            readme_content = None
            found_url = None

            for branch in branches:
                for readme_file in readme_files:
                    url = f"https://raw.githubusercontent.com/{repo}/refs/heads/{branch}/{readme_file}"
                    try:
                        response = requests.get(url, timeout=20)
                        if response.status_code == 200:
                            readme_content = response.text
                            found_url = url
                            break
                    except:
                        continue
                if readme_content:
                    break

            if readme_content:
                # é™åˆ¶å†…å®¹é•¿åº¦ï¼Œé¿å…è¿‡é•¿
                if len(readme_content) > 50000:  # 50KBé™åˆ¶
                    readme_content = readme_content[:50000] + "\n\n... [å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­] ..."

                results.append(f"âœ… æˆåŠŸè·å– (æ¥æº: {found_url})")
                results.append(f"ä»“åº“åç§°: {repo}")
                results.append("README:")
                results.append(readme_content)
                results.append("---\n\n")
            else:
                results.append(f"âŒ æœªæ‰¾åˆ°READMEæ–‡ä»¶")
                results.append(f"   å·²å°è¯•åˆ†æ”¯: {', '.join(branches)}")
                results.append(f"   å·²å°è¯•æ–‡ä»¶: {', '.join(readme_files)}")
                results.append(f"ä»“åº“åç§°: {repo}")
                results.append("README: æœªæ‰¾åˆ°å¯è¯»å–çš„READMEæ–‡ä»¶")
                results.append("---\n\n")

        except Exception as e:
            results.append(f"âŒ å¤„ç†ä»“åº“ {repo} æ—¶å‡ºé”™: {str(e)}")
            results.append(f"ä»“åº“åç§°: {repo}")
            results.append(f"README: è·å–å¤±è´¥ - {str(e)}")
            results.append("---")

    results.append("ğŸ’¡ å»ºè®®ä¸‹ä¸€æ­¥æ“ä½œï¼š")
    results.append("- 1. åˆ†ææ¯ä¸ªé¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯å’ŒæŠ€æœ¯ç‰¹ç‚¹")
    results.append("- 2. å¦‚æœæœ‰ç‰¹åˆ«æ„Ÿå…´è¶£çš„é¡¹ç›®ï¼Œå¯ä»¥è¿›ä¸€æ­¥ç ”ç©¶å…¶å®ç°ç»†èŠ‚")
    results.append("- 3. æ€»ç»“é¡¹ç›®çš„æŠ€æœ¯äº®ç‚¹å’Œåº”ç”¨åœºæ™¯")

    return "\n".join(results)


if __name__ == "__main__":
    # è¿è¡ŒMCP server
    mcp.run()